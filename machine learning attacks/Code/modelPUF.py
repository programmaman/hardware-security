import numpy as np
import random
import argparse
import math
import tensorflow as tf

from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.models import Sequential

# can uncomment this if you are using an RTX GPU
# physical_devices = tf.config.list_physical_devices('GPU') 
# tf.config.experimental.set_memory_growth(physical_devices[0], True)

def main():
    # extra codes that allows this script to work with command line arguments (just for testing)
    parser = argparse.ArgumentParser(description='CLI Interface for building/training a neural network to model a PUF from raw data.')
    parser.add_argument('-c','--challangefile', help='path/name of file to read challange data from', required=True)
    parser.add_argument('-r','--responsefile',  help='path/name of file to read response data from',  required=True)
    parser.add_argument('-p','--percentdata',   help='percentage of supplied training data to use for testing', required=True)

    args  = vars(parser.parse_args())
    cfile = args['challangefile']
    rfile = args['responsefile']
    p     = float(args['percentdata'])
    
    ''' This is how you can interface in another script: '''
    # Setup CRP dataset format for the PUF model
    crpData = ChallengeResponseSet(cfilename=cfile, rfilename=rfile)

    # Input the CRP dataset to the pufModel
    puf = pufModel(crpData)
    # Splits the CRP dataset in train/test subsets. p (float): percentage of data to use for training
    crpData.train_test_split(p)
    # Trains the models with the CRP train subset 
    puf.train(crpData)
    # Test the models with the CRP test subset and computes its accuracy.
    accuracy = puf.test(crpData)
    
    print(accuracy)

    # can save the weights to a file
    # puf.save_weights('pufModel-16bit.h5')


class ChallengeResponseSet:
    """
        A set of challenges and corresponding responses. 
        Provides a neat interface with useful functions to work with your CRP data.

        Was adapted from a module within the Pypuf repository: https://github.com/nils-wisiol/pypuf
    """

    def __init__(self, cfilename=None, rfilename=None, challenges=None, responses=None):
        """
        Create a set of challenges and corresponding responses. Note that the order of the
        challenges and responses parameter is relevant.
        :param cfilename: file name with list of challenges
        :param rfilename: file name with list of responses, ordered accordingly to cfilename
        :param challenges: List of challenges
        :param responses: List of responses, ordered accordingly
        """
        if (cfilename is not None) and (rfilename is not None):
            self.challenges, self.responses = self.read_crps(cfilename, rfilename, 16, 2)
        elif challenges is not None and responses is not None:
            self.challenges, self.responses = challenges, responses
        else:
            raise Exception("Error: missing file name(s)")

        self.train, self.valid, self.test = [None] * 3
        assert len(self.challenges) == len(self.responses)
        self.N = len(self.challenges)
        self.clength = self.challenges.shape[1]


    def read_crps(self, cfilename, rfilename, c_base=16, r_base=2):
        """ Reads the challange and resp file generated by gen_crps.py and returns a pypuf CRP dataset

        Args:
            filename (str): path-to/filename
            c_base (int): base of the challenges format, e.g., 2 for bin, 16 for hex
            c_base (int): base of the responses format,  e.g., 2 for bin, 16 for hex

        Returns:
            pypuf.tools.ChallengeResponseSet()
        """
        if ".npz" in cfilename and ".npz" in rfilename:
            cdata = np.load(cfilename)
            rdata = np.load(rfilename)
            n = len(cdata['challenge'])
            challengeSize = len(cdata['challenge'][0]) * math.log(c_base, 2)
            numPUFs       = len(rdata['response'][0])  * math.log(r_base, 2)

            # read into np array 
            C = np.array([int(s, c_base) for s in cdata['challenge']], dtype=np.uint64)
            R = np.array([int(s, r_base) for s in rdata['response']], dtype=np.uint16)

            # convert to binary representation
            challenges = np.array(((C[:, None] & (1 << np.arange(challengeSize, dtype=np.uint64)[::-1])) > 0), dtype=int)
            responses = np.array(((R[:, None] & (1 << np.arange(numPUFs, dtype=np.uint16)[::-1]) > 0)), dtype=int)
        else:
             raise Exception("Error: incorrect file format. Must be '.npz'")
                

        if len(responses.shape) > 1:
            # get PUF with closest ratio to 0.5
            responsesHeuristic = np.abs((np.sum(responses, axis=0) / n) - 0.5)
            test = np.argmax(responsesHeuristic)
            
            # get "best" responses
            bestPUFResponses = responses[:, test]
        else:
            bestPUFResponses = responses

        # convert CRPs to 1/-1
        bestPUFResponses[bestPUFResponses == 1] = -1
        bestPUFResponses[bestPUFResponses == 0] = 1 
        challenges[challenges == 1] = -1
        challenges[challenges == 0] = 1

        # convert challenges to parity/delay vectors
        challenges = np.cumprod(challenges, axis=1, dtype=np.int8)

        # add parity bit, is this still necessary? no, just use parity vector
        # challenges = np.hstack([challenges, parity])
        return challenges.astype(float), bestPUFResponses.astype(float)

    def random_subset(self, N):
        """
        Gives a random subset of this challenge response set.
        :param N: Either a relative (to the total number) or absolute number of challenges.
        :return: A random subset samples from this challenge response set.
        """
        if N < 1:
            N = int(self.N * N)
        return self.subset(random.sample(range(self.N), N))

    def train_test_split(self, pTrain):
        """ Performs a train test split on the data using the percentage of data for training as an argument

        Args:
            pTrain (float): percentage of data to use for training
        """
        N = int(pTrain * self.N)
        inds = [*range(self.N)]
        random.shuffle(inds)

        self.train = self.subset(inds[:N])
        self.test = self.subset(inds[N:])

        return self.train, self.test

    def train_valid_test_split(self, pTrain, pValid):
        """ Performs a train test split on the data using the percentage of data for training as an argument

        Args:
            pTrain (float): percentage of data to use for training
        """
        nTrain = int(pTrain * self.N)
        nValid = nTrain + int(pValid * self.N)
        inds = [*range(self.N)]
        random.shuffle(inds)

        self.train = self.subset(inds[:nTrain])
        self.valid = self.subset(inds[nTrain:nValid])
        self.test = self.subset(inds[nValid:])

        return self.train, self.valid, self.test        

    def block_subset(self, i, total):
        """
        Gives the i-th block of this challenge response set.
        :param i: Index of the block that is to be returned.
        :param total: Total number of blocks.
        :return: A challenge response set.
        """
        return self.subset(slice(
            int(i / total * self.N),
            int((i + 1) / total * self.N)
        ))

    def subset(self, subset_slice):
        """
        Gives the subset of this challenge response set defined by the slice given.
        :param subset_slice: A python array slice
        :return: A challenge response set defined accordingly
        """
        return ChallengeResponseSet(
            challenges=self.challenges[subset_slice],
            responses=self.responses[subset_slice]
        )

class pufModel:
    """
        A class which interfaces with Tensorflow/Keras and creates a DNN model to model an APUF.
    """

    @staticmethod
    def loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:
        return tf.keras.losses.binary_crossentropy(.5 - .5 * y_true, .5 - .5 * y_pred)

    @staticmethod
    def accuracy(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:
        return tf.keras.metrics.binary_accuracy(.5 - .5 * y_true, .5 - .5 * y_pred)

    def __init__(self, crpData=None, verbose=0):
        self.crpData = crpData
        self.clength = crpData.clength
        model = Sequential()
        model.add(Input(shape=(self.clength,)))
        model.add(Dense(2, activation='relu'))
        # model.add(Dropout(0.5))
        # model.add(BatchNormalization())
        # model.add(Dense(32, activation='relu'))
        # model.add(Dropout(0.5))
        # model.add(BatchNormalization())
        # model.add(Dense(self.clength // 6, activation='relu'))
        # model.add(Dropout(0.25))
        # model.add(BatchNormalization())
        model.add(Dense(1, activation='tanh'))
        # model.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])
        model.compile(loss=self.loss, optimizer=tf.keras.optimizers.Adam(), metrics=[self.accuracy])

        self.model = model
        self.initial_weights = self.model.get_weights()
        self.verbose = verbose

    def reset_model(self):
        self.model.set_weights(self.initial_weights)

    def train(self, crps):
        trainX = crps.train.challenges
        trainY = crps.train.responses

        self.model.fit(
            trainX, trainY,
            # validation_data=(self._valid.challenges, self._valid.responses),
            batch_size=500, epochs=100, verbose = self.verbose
        )

    def test(self, crps):
        testX = crps.test.challenges
        testY = crps.test.responses
        self.model.evaluate(testX, testY, verbose=self.verbose)
        # if the prediction probability >= 0.5, then it predicts '1' as the response. Otherwise, '0'.
        pred_y = self.model.predict_on_batch(testX).reshape(-1)
        
        acc = self.accuracy(testY, pred_y)
        
        print(f"Accuracy on {len(pred_y)} unseen challenges is: {acc}")
        return float(acc)

    def save_weights(self, filename):
        self.model.save_weights(filename)

    def load_weights(self, filename):
        self.model.load_weights(filename)


if __name__ == '__main__':
    main()